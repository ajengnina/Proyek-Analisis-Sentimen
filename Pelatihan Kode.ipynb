{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c57a3c73-433d-49f2-8057-915a1bf97fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning tiktok.csv...\n",
      "tiktok_cleaned.csv saved ✅\n",
      "\n",
      "Cleaning shopee.csv...\n",
      "shopee_cleaned.csv saved ✅\n",
      "\n",
      "Cleaning gojek.csv...\n",
      "gojek_cleaned.csv saved ✅\n",
      "\n",
      "Cleaning ruangguru.csv...\n",
      "ruangguru_cleaned.csv saved ✅\n",
      "\n",
      "Cleaning whatsapp.csv...\n",
      "whatsapp_cleaned.csv saved ✅\n",
      "\n",
      "SEMUA FILE TELAH DIBERSIHKAN ✅\n"
     ]
    }
   ],
   "source": [
    "# PEMBERSIHAN & PELABELAN\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import os\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "\n",
    "# --- 2.1 Pembersihan Teks --- #\n",
    "\n",
    "# Inisialisasi stopword\n",
    "stop_factory = StopWordRemoverFactory()\n",
    "stopwords = stop_factory.get_stop_words()\n",
    "\n",
    "# Fungsi pembersihan teks\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'[' + string.punctuation + ']', ' ', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    text = ' '.join([word for word in text.split() if word not in stopwords])\n",
    "    return text\n",
    "\n",
    "# Daftar file hasil scraping\n",
    "files = ['tiktok.csv', 'shopee.csv', 'gojek.csv', 'ruangguru.csv', 'whatsapp.csv']\n",
    "\n",
    "# Proses cleaning\n",
    "for file in files:\n",
    "    if os.path.exists(file):\n",
    "        print(f\"Cleaning {file}...\")\n",
    "        df = pd.read_csv(file)\n",
    "        if 'content' in df.columns:\n",
    "            df['cleaned'] = df['content'].apply(clean_text)\n",
    "            df.to_csv(file.replace('.csv', '_cleaned.csv'), index=False)\n",
    "            print(f\"{file.replace('.csv', '_cleaned.csv')} saved ✅\\n\")\n",
    "        else:\n",
    "            print(f\"Kolom 'content' tidak ditemukan dalam {file} ⚠️\\n\")\n",
    "    else:\n",
    "        print(f\"File {file} tidak ditemukan ⚠️\\n\")\n",
    "\n",
    "print(\"SEMUA FILE TELAH DIBERSIHKAN ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "efffb43f-7ae3-48eb-96fc-d3e95bc7dfcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeling tiktok_cleaned.csv...\n",
      "tiktok_labeled.csv saved ✅\n",
      "\n",
      "Labeling shopee_cleaned.csv...\n",
      "shopee_labeled.csv saved ✅\n",
      "\n",
      "Labeling gojek_cleaned.csv...\n",
      "gojek_labeled.csv saved ✅\n",
      "\n",
      "Labeling ruangguru_cleaned.csv...\n",
      "ruangguru_labeled.csv saved ✅\n",
      "\n",
      "Labeling whatsapp_cleaned.csv...\n",
      "whatsapp_labeled.csv saved ✅\n",
      "\n",
      "SEMUA FILE TELAH DILABELI ✅\n"
     ]
    }
   ],
   "source": [
    "# --- 2.2 Pelabelan Semi-Otomatis --- #\n",
    "\n",
    "# Kata kunci untuk labeling\n",
    "positive_words = ['bagus', 'mantap', 'cepat', 'puas', 'keren', 'lancar']\n",
    "negative_words = ['jelek', 'error', 'lemot', 'buruk', 'parah', 'gagal']\n",
    "\n",
    "# Fungsi labeling berbasis kata kunci\n",
    "def label_sentiment(text):\n",
    "    if isinstance(text, str):\n",
    "        if any(word in text for word in positive_words):\n",
    "            return 'positif'\n",
    "        elif any(word in text for word in negative_words):\n",
    "            return 'negatif'\n",
    "        else:\n",
    "            return 'netral'\n",
    "    else:\n",
    "        return 'netral'\n",
    "\n",
    "# Labeling untuk semua file cleaned\n",
    "for file in files:\n",
    "    cleaned_file = file.replace('.csv', '_cleaned.csv')\n",
    "    if os.path.exists(cleaned_file):\n",
    "        print(f\"Labeling {cleaned_file}...\")\n",
    "        df = pd.read_csv(cleaned_file)\n",
    "        if 'cleaned' in df.columns:\n",
    "            df['sentiment'] = df['cleaned'].apply(label_sentiment)\n",
    "            df.to_csv(file.replace('.csv', '_labeled.csv'), index=False)\n",
    "            print(f\"{file.replace('.csv', '_labeled.csv')} saved ✅\\n\")\n",
    "        else:\n",
    "            print(f\"Kolom 'cleaned' tidak ditemukan dalam {cleaned_file} ⚠️\\n\")\n",
    "    else:\n",
    "        print(f\"File {cleaned_file} tidak ditemukan ⚠️\\n\")\n",
    "\n",
    "print(\"SEMUA FILE TELAH DILABELI ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c84c925-8f1c-4514-8857-43d267a1a54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   air  aja       aku  akun  apa  apk  aplikasi  aplikasinya  app  asik  ...  \\\n",
      "0  0.0  0.0  0.000000   0.0  0.0  0.0  0.000000          0.0  0.0   0.0  ...   \n",
      "1  0.0  0.0  0.462748   0.0  0.0  0.0  0.000000          0.0  0.0   0.0  ...   \n",
      "2  0.0  0.0  0.000000   0.0  0.0  0.0  0.369211          0.0  0.0   0.0  ...   \n",
      "3  0.0  0.0  0.000000   0.0  0.0  0.0  0.000000          0.0  0.0   0.0  ...   \n",
      "4  0.0  0.0  0.000000   0.0  0.0  0.0  0.000000          0.0  0.0   0.0  ...   \n",
      "\n",
      "   versi  very  video  vidio  yah  yes   yg  you  على   من  \n",
      "0    0.0   0.0    0.0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "1    0.0   0.0    0.0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2    0.0   0.0    0.0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3    0.0   0.0    0.0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4    0.0   0.0    0.0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[5 rows x 200 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "# Contoh load data\n",
    "df = pd.read_csv('tiktok_labeled.csv')\n",
    "\n",
    "# Pastikan tidak ada NaN atau data kosong\n",
    "df['cleaned'] = df['cleaned'].fillna('')\n",
    "\n",
    "# Inisialisasi TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=200)\n",
    "\n",
    "# Terapkan TF-IDF\n",
    "X_tfidf = tfidf.fit_transform(df['cleaned'])\n",
    "\n",
    "# Konversi ke DataFrame untuk melihat hasil\n",
    "tfidf_df = pd.DataFrame(X_tfidf.toarray(), columns=tfidf.get_feature_names_out())\n",
    "\n",
    "# Lihat beberapa baris pertama\n",
    "print(tfidf_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "82c1830e-ea83-43b7-8558-10c2cf92455b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluasi Model:\n",
      "Logistic Regression: Accuracy=0.9444, Precision=0.9482, Recall=0.9444, F1-score=0.9329\n",
      "Random Forest: Accuracy=0.9500, Precision=0.9517, Recall=0.9500, F1-score=0.9390\n",
      "Neural Network (MLP): Accuracy=0.9278, Precision=0.9290, Recall=0.9278, F1-score=0.9170\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Load data yang sudah dibersihkan dan dilabeli\n",
    "df = pd.read_csv('tiktok_labeled.csv')\n",
    "\n",
    "# Tangani NaN dengan mengganti dengan string kosong\n",
    "df['cleaned'] = df['cleaned'].fillna('')\n",
    "\n",
    "# Ekstraksi fitur TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X_tfidf = tfidf.fit_transform(df['cleaned'])\n",
    "y = df['sentiment'].apply(lambda x: 1 if x == 'positif' else (0 if x == 'negatif' else 2))  # Mengubah label menjadi numerik\n",
    "\n",
    "# Pembagian data menjadi training dan testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Fungsi untuk mengevaluasi model\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=1)  # Menangani label dengan tidak ada prediksi\n",
    "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=1)        # Menangani label dengan tidak ada prediksi\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=1)                # Menangani label dengan tidak ada prediksi\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# 1. Logistic Regression\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "logreg_accuracy, logreg_precision, logreg_recall, logreg_f1 = evaluate_model(logreg, X_test, y_test)\n",
    "\n",
    "# 2. Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_accuracy, rf_precision, rf_recall, rf_f1 = evaluate_model(rf, X_test, y_test)\n",
    "\n",
    "# 3. Neural Network (MLP)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500)\n",
    "mlp.fit(X_train, y_train)\n",
    "mlp_accuracy, mlp_precision, mlp_recall, mlp_f1 = evaluate_model(mlp, X_test, y_test)\n",
    "\n",
    "# Evaluasi model\n",
    "logreg_accuracy, logreg_precision, logreg_recall, logreg_f1 = evaluate_model(logreg, X_test, y_test)\n",
    "rf_accuracy, rf_precision, rf_recall, rf_f1 = evaluate_model(rf, X_test, y_test)\n",
    "mlp_accuracy, mlp_precision, mlp_recall, mlp_f1 = evaluate_model(mlp, X_test, y_test)\n",
    "\n",
    "# Hasil evaluasi\n",
    "print(\"Evaluasi Model:\")\n",
    "print(f\"Logistic Regression: Accuracy={logreg_accuracy:.4f}, Precision={logreg_precision:.4f}, Recall={logreg_recall:.4f}, F1-score={logreg_f1:.4f}\")\n",
    "print(f\"Random Forest: Accuracy={rf_accuracy:.4f}, Precision={rf_precision:.4f}, Recall={rf_recall:.4f}, F1-score={rf_f1:.4f}\")\n",
    "print(f\"Neural Network (MLP): Accuracy={mlp_accuracy:.4f}, Precision={mlp_precision:.4f}, Recall={mlp_recall:.4f}, F1-score={mlp_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "abcde5e0-64af-4405-8dab-09bae21e2807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentimen untuk teks 'Aplikasi ini sangat bagus, mudah digunakan dan cepat.' adalah: 1\n"
     ]
    }
   ],
   "source": [
    "# Fungsi untuk melakukan prediksi sentimen pada teks baru\n",
    "def predict_sentiment(text, model, tfidf_vectorizer=None):\n",
    "    # Pembersihan teks\n",
    "    text_cleaned = clean_text(text)\n",
    "    \n",
    "    # Ekstraksi fitur (menggunakan TF-IDF jika model menggunakan TF-IDF)\n",
    "    if tfidf_vectorizer:\n",
    "        text_tfidf = tfidf_vectorizer.transform([text_cleaned])\n",
    "        pred = model.predict(text_tfidf)\n",
    "    else:\n",
    "        # Jika menggunakan model yang sudah dilatih dengan representasi lain seperti Word2Vec\n",
    "        tokens = text_cleaned.split()\n",
    "        text_w2v = get_avg_w2v(tokens, model_w2v)\n",
    "        pred = model.predict([text_w2v])\n",
    "    \n",
    "    # Mengembalikan prediksi sentimen\n",
    "    return pred[0]\n",
    "\n",
    "# Contoh penggunaan untuk teks baru:\n",
    "text_input = \"Aplikasi ini sangat bagus, mudah digunakan dan cepat.\"\n",
    "sentiment_prediction = predict_sentiment(text_input, logreg, tfidf)\n",
    "\n",
    "print(f\"Sentimen untuk teks '{text_input}' adalah: {sentiment_prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c98a28-c648-45aa-bf4a-53c29a0f3bb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
